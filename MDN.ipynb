{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import generate_dataset, get_normalized_adj, get_Laplace, calculate_random_walk_matrix,nb_zeroinflated_nll_loss,nb_zeroinflated_draw,nb_MDN_nll_loss\n",
    "from model import *\n",
    "import random,os,copy\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.stats import nbinom\n",
    "import pickle as pk\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "# Parameters\n",
    "torch.manual_seed(0)\n",
    "device = 'cpu'\n",
    "#torch.device('cuda') \n",
    "A = np.load('/Users/pipipu/Desktop/STZINB/ny_data_full_5min/adj_rand0.npy') # change the loading folder\n",
    "X = np.load('/Users/pipipu/Desktop/STZINB/ny_data_full_5min/cta_samp_rand0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps_output = 4 \n",
    "num_timesteps_input = num_timesteps_output\n",
    "\n",
    "space_dim = X.shape[1]\n",
    "batch_size = 4\n",
    "hidden_dim_s = 70\n",
    "hidden_dim_t = 7\n",
    "rank_s = 20\n",
    "rank_t = 4\n",
    "n_gaussian = 2\n",
    "\n",
    "epochs = 50 #500\n",
    "\n",
    "# Initial networks\n",
    "TCN1 = B_TCN(space_dim, hidden_dim_t, kernel_size=3).to(device=device)\n",
    "TCN2 = B_TCN(hidden_dim_t, rank_t, kernel_size = 3, activation = 'linear').to(device=device)\n",
    "TCN3 = B_TCN(rank_t, hidden_dim_t, kernel_size= 3).to(device=device)\n",
    "TNB = MDN(hidden_dim_t,space_dim,n_gaussian).to(device=device)\n",
    "#NBNorm_ZeroInflated(hidden_dim_t,space_dim).to(device=device)\n",
    "SCN1 = D_GCN(num_timesteps_input, hidden_dim_s, 3).to(device=device)\n",
    "SCN2 = D_GCN(hidden_dim_s, rank_s, 2, activation = 'linear').to(device=device)\n",
    "SCN3 = D_GCN(rank_s, hidden_dim_s, 2).to(device=device)\n",
    "SNB = MDN(hidden_dim_s,num_timesteps_output,n_gaussian).to(device=device)\n",
    "#NBNorm_ZeroInflated(hidden_dim_s,num_timesteps_output).to(device=device)\n",
    "STmodel = ST_MDN(SCN1, SCN2, SCN3, TCN1, TCN2, TCN3, SNB,TNB).to(device=device)\n",
    "#ST_NB_ZeroInflated(SCN1, SCN2, SCN3, TCN1, TCN2, TCN3, SNB,TNB).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4489, 1, 100) (4489, 4489)\n",
      "input shape:  torch.Size([53, 4489, 4, 1]) torch.Size([3, 4489, 4, 1]) torch.Size([23, 4489, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "X = X.T\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "X = X.reshape((X.shape[0],1,X.shape[1]))\n",
    "X = X[:,:,:100]\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.7)\n",
    "print(X.shape,A.shape)\n",
    "\n",
    "# normalization\n",
    "max_value = np.max(X[:, :, :split_line1])\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "training_input, training_target = generate_dataset(train_original_data,\n",
    "                                                    num_timesteps_input=num_timesteps_input,\n",
    "                                                    num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = generate_dataset(val_original_data,\n",
    "                                            num_timesteps_input=num_timesteps_input,\n",
    "                                            num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = generate_dataset(test_original_data,\n",
    "                                            num_timesteps_input=num_timesteps_input,\n",
    "                                            num_timesteps_output=num_timesteps_output)\n",
    "print('input shape: ',training_input.shape,val_input.shape,test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_wave = get_normalized_adj(A)\n",
    "A_q = torch.from_numpy((calculate_random_walk_matrix(A_wave).T).astype('float32'))\n",
    "A_h = torch.from_numpy((calculate_random_walk_matrix(A_wave.T).T).astype('float32'))\n",
    "A_q = A_q.to(device=device)\n",
    "A_h = A_h.to(device=device)\n",
    "# Define the training process\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(STmodel.parameters(), lr=1e-2)\n",
    "training_nll   = []\n",
    "validation_nll = []\n",
    "validation_mae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pipipu/miniconda3/envs/DLML/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.100705010550364\n",
      "19.010907581874303\n",
      "18.829890523638046\n",
      "18.785037721906388\n",
      "18.767018726893834\n",
      "18.761702946254186\n",
      "18.75909764426095\n",
      "18.757761682782853\n",
      "18.755827358790807\n",
      "18.758252825055802\n",
      "18.755607060023717\n",
      "18.749221801757812\n",
      "18.748316083635604\n",
      "18.75291783469064\n",
      "18.755890165056503\n",
      "18.75613921029227\n",
      "18.755666732788086\n",
      "18.750990867614746\n",
      "18.74681200299944\n",
      "18.75399044581822\n",
      "18.753967557634628\n",
      "18.752950259617396\n",
      "18.7479122706822\n",
      "18.750214304242814\n",
      "18.752748216901505\n",
      "18.74919182913644\n",
      "18.751228060041154\n",
      "18.748877797807967\n",
      "18.745121955871582\n",
      "18.746251787458146\n",
      "18.744773592267716\n",
      "18.751914296831405\n",
      "18.753116880144393\n",
      "18.752203941345215\n",
      "18.745682307652064\n",
      "18.751022611345565\n",
      "18.751975331987655\n",
      "18.745358330862864\n",
      "18.7504916872297\n",
      "18.751978874206543\n",
      "18.750537736075266\n",
      "18.752279145377024\n",
      "18.75174249921526\n",
      "18.750738961356028\n",
      "18.75005681174142\n",
      "18.74631827218192\n",
      "18.751503671918595\n",
      "18.75201920100621\n",
      "18.748608589172363\n",
      "18.745958873203822\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    ## Step 1, training\n",
    "    \"\"\"\n",
    "    # Begin training, similar training procedure from STGCN\n",
    "    Trains one epoch with the given data.\n",
    "    :param training_input: Training inputs of shape (num_samples, num_nodes,\n",
    "    num_timesteps_train, num_features).\n",
    "    :param training_target: Training targets of shape (num_samples, num_nodes,\n",
    "    num_timesteps_predict).\n",
    "    :param batch_size: Batch size to use during training.\n",
    "    \"\"\"\n",
    "    permutation = torch.randperm(training_input.shape[0])\n",
    "    epoch_training_losses = []\n",
    "    for i in range(0, training_input.shape[0], batch_size):\n",
    "        STmodel.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        X_batch, y_batch = training_input[indices], training_target[indices]\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        y_batch = y_batch.to(device=device)\n",
    "    \n",
    "        pi_train,pi_g_train,mu_g_train,sigma_g_train = STmodel(X_batch,A_q,A_h)\n",
    "        #n_train,p_train,pi_train = STmodel(X_batch,A_q,A_h)\n",
    "\n",
    "\n",
    "        loss = nb_MDN_nll_loss(y_batch,pi_train, pi_g_train,mu_g_train,sigma_g_train)\n",
    "        \n",
    "        #loss = nb_zeroinflated_nll_loss(y_batch,n_train,p_train,pi_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_losses.append(loss.detach().cpu().numpy())\n",
    "    training_nll.append(sum(epoch_training_losses)/len(epoch_training_losses))\n",
    "    print(sum(epoch_training_losses)/len(epoch_training_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/4b0w_54n0lg5yfw096pph8bc0000gn/T/ipykernel_80806/1326070190.py:15: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  validation_nll.append(np.asscalar(val_loss.detach().numpy()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7925)\n",
      "tensor(0.2075)\n",
      "tensor(0.7925)\n",
      "tensor(0.2075)\n",
      "tensor(0.7925)\n",
      "tensor(0.2075)\n",
      "tensor(0.7925)\n",
      "tensor(0.2075)\n",
      "tensor(0.7925)\n",
      "tensor(0.2075)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_input \u001b[39m=\u001b[39m val_input\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m val_target \u001b[39m=\u001b[39m val_target\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> 9\u001b[0m pi_val,pi_g_val,mu_g_val,sigma_g_val \u001b[39m=\u001b[39m STmodel(val_input,A_q,A_h)\n\u001b[1;32m     10\u001b[0m \u001b[39m#n_val,p_val,pi_val = STmodel(val_input,A_q,A_h)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#print('Pi_val,mean,min,max',torch.mean(pi_val),torch.min(pi_val),torch.max(pi_val))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m val_loss \u001b[39m=\u001b[39m nb_MDN_nll_loss(val_target,pi_val, pi_g_val,mu_g_val,sigma_g_val)\n",
      "File \u001b[0;32m~/miniconda3/envs/DLML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/STZINB/model.py:552\u001b[0m, in \u001b[0;36mST_MDN.forward\u001b[0;34m(self, X, A_q, A_h)\u001b[0m\n\u001b[1;32m    550\u001b[0m X_s2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSC2(X_s1, A_q, A_h) \u001b[39m#num_nodes, rank\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspace_factors \u001b[39m=\u001b[39m X_s2\n\u001b[0;32m--> 552\u001b[0m X_s3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSC3(X_s2, A_q, A_h)\n\u001b[1;32m    553\u001b[0m _b,_n,_hs \u001b[39m=\u001b[39m X_s3\u001b[39m.\u001b[39mshape\n\u001b[1;32m    554\u001b[0m pi_s, pi_g_s,mu_g_s,sigma_g_s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSNB(X_s3\u001b[39m.\u001b[39mview(_b,_n,_hs,\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/DLML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/STZINB/model.py:182\u001b[0m, in \u001b[0;36mD_GCN.forward\u001b[0;34m(self, X, A_q, A_h)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m support \u001b[39min\u001b[39;00m supports:\n\u001b[1;32m    181\u001b[0m     x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(support, x0)\n\u001b[0;32m--> 182\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_concat(x, x1)\n\u001b[1;32m    183\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morders \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    184\u001b[0m         x2 \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmm(support, x1) \u001b[39m-\u001b[39m x0\n",
      "File \u001b[0;32m~/Desktop/STZINB/model.py:161\u001b[0m, in \u001b[0;36mD_GCN._concat\u001b[0;34m(self, x, x_)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_concat\u001b[39m(\u001b[39mself\u001b[39m, x, x_):\n\u001b[1;32m    160\u001b[0m     x_ \u001b[39m=\u001b[39m x_\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat([x, x_], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        STmodel.eval()\n",
    "        val_input = val_input.to(device=device)\n",
    "        val_target = val_target.to(device=device)\n",
    "\n",
    "        pi_val,pi_g_val,mu_g_val,sigma_g_val = STmodel(val_input,A_q,A_h)\n",
    "        #n_val,p_val,pi_val = STmodel(val_input,A_q,A_h)\n",
    "        #print('Pi_val,mean,min,max',torch.mean(pi_val),torch.min(pi_val),torch.max(pi_val))\n",
    "\n",
    "        val_loss = nb_MDN_nll_loss(val_target,pi_val, pi_g_val,mu_g_val,sigma_g_val)\n",
    "        #val_loss    = nb_zeroinflated_nll_loss(val_target,n_val,p_val,pi_val).to(device=\"cpu\")\n",
    "        validation_nll.append(np.asscalar(val_loss.detach().numpy()))\n",
    "       \n",
    "        # Calculate the expectation value\n",
    "        \n",
    "        \n",
    "        val_pred = torch.abs(1-pi_val) *  torch.sum((pi_g_val * mu_g_val),dim = -1)\n",
    "        print(torch.sum((pi_g_val * mu_g_val),dim = -1))\n",
    "        #val_pred = (1-pi_val.detach().cpu().numpy())*(n_val.detach().cpu().numpy()/p_val.detach().cpu().numpy()-n_val.detach().cpu().numpy()) # pipred\n",
    "        #print(val_pred.mean(),pi_val.detach().cpu().numpy().min())\n",
    "        mae = torch.mean(torch.abs(val_pred - val_target.detach().cpu().numpy()))\n",
    "        \n",
    "        #validation_mae.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
